import streamlit as st
import google.generativeai as genai
from PIL import Image
import os
from dotenv import load_dotenv

# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…ÙØ³Ø± Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ÙŠØ©", layout="wide", page_icon="ğŸ©º")

# --- ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø´Ø§Øª) ---
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Sidebar) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063176.png", width=100)
    st.title("Ø¹Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚")
    st.info("""
    Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ ÙˆØ´Ø±Ø­Ù‡Ø§ØŒ Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
    """)
    
    # Ø²Ø± Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· ÙƒÙ„ Ø´ÙŠØ¡
    if st.button("ğŸ—‘ï¸ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯"):
        st.session_state.analysis_result = None
        st.session_state.messages = []
        st.rerun()
        
    st.write("---")
    st.write("ğŸ‘©â€ğŸ’» **ØªØ·ÙˆÙŠØ±:** Ù‡ÙŠÙØ§Ø¡")
    st.error("âš ï¸ **ØªÙ†Ø¨ÙŠÙ‡:** Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø§Ø³ØªØ±Ø´Ø§Ø¯ ÙÙ‚Ø·.")

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ”¬ Ù…ÙØ³Ø± Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø°ÙƒÙŠ")
st.markdown("---")

# Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
uploaded_file = st.file_uploader("Ù‚Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù‡Ù†Ø§ (JPG, PNG)...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø´Ø§Ø´Ø© (Ø§Ù„ØµÙˆØ±Ø© ÙŠÙ…ÙŠÙ† - ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª ÙŠØ³Ø§Ø±)
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©", use_container_width=True)
    
    with col2:
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ ØªØ­Ù„ÙŠÙ„ Ù…Ø­ÙÙˆØ¸ØŒ Ø§Ø¹Ø±Ø¶ Ø²Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if st.session_state.analysis_result is None:
            st.write("### âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
            mode = st.radio("ÙƒÙŠÙ ØªØ±ÙŠØ¯ Ø´Ø±Ø­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŸ", ["Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· (Ø¹Ø§Ù…ÙŠ ÙˆØ³Ù‡Ù„)", "Ø´Ø±Ø­ Ø¹Ù„Ù…ÙŠ (Ù…ÙØµÙ„)"])
            
            if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¢Ù† âš¡", type="primary"):
                model = genai.GenerativeModel('models/gemini-flash-latest')
                
                with st.spinner('Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆÙÙ‡Ù… Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø·Ø¨ÙŠØ©...'):
                    try:
                        style_instruction = "Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø·Ù…Ø¦Ù†Ø©." if mode == "Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· (Ø¹Ø§Ù…ÙŠ ÙˆØ³Ù‡Ù„)" else "Ø§Ø³ØªØ®Ø¯Ù… Ù…ØµØ·Ù„Ø­Ø§Øª Ø·Ø¨ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø©."
                        
                        prompt = f"""
                        Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø·Ø¨ÙŠ. {style_instruction}
                        Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø©:
                        1. Ø£Ù†Ø´Ø¦ Ø¬Ø¯ÙˆÙ„Ø§Ù‹ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø§Ù„Ø§Ø³Ù… | Ø§Ù„Ù‚ÙŠÙ…Ø© | Ø§Ù„Ø­Ø§Ù„Ø© âœ…/âš ï¸).
                        2. Ø§ÙƒØªØ¨ Ù…Ù„Ø®ØµØ§Ù‹ Ø³Ø±ÙŠØ¹Ø§Ù‹ Ù„Ø£Ù‡Ù… Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª.
                        """
                        
                        response = model.generate_content([prompt, image])
                        
                        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙŠ Ù„Ø§ ØªØ®ØªÙÙŠ
                        st.session_state.analysis_result = response.text
                        st.rerun() # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø© Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø©
                        
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø§Ø¹Ø±Ø¶Ù‡Ø§
        else:
            st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
            st.markdown("### ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            st.markdown(st.session_state.analysis_result)

    # --- Ù‚Ø³Ù… Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© (ÙŠØ¸Ù‡Ø± ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„) ---
    if st.session_state.analysis_result is not None:
        st.markdown("---")
        st.subheader("ğŸ’¬ Ø¯ÙƒØªÙˆØ±ØŒ Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±...")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Ø®Ø§Ù†Ø© Ø§Ù„Ø³Ø¤Ø§Ù„
        if user_question := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ (Ù…Ø«Ù„Ø§Ù‹: Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„ØºØ°Ø§Ø¦ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ØŸ)"):
            
            # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            st.session_state.messages.append({"role": "user", "content": user_question})
            with st.chat_message("user"):
                st.markdown(user_question)

            # Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
            with st.chat_message("assistant"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙƒØªØ§Ø¨Ø©..."):
                    model = genai.GenerativeModel('models/gemini-flash-latest')
                    
                    # Ù†Ø±Ø³Ù„ Ù„Ù‡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© + Ø§Ù„ØµÙˆØ±Ø©
                    chat_prompt = f"""
                    Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø·Ø¨ÙŠ. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ³Ø£Ù„ Ø¹Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±ÙÙ‚ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.
                    Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_question}
                    Ø£Ø¬Ø¨ Ø¨Ø§Ø®ØªØµØ§Ø± ÙˆØ¨Ø·Ø±ÙŠÙ‚Ø© Ù…ÙÙŠØ¯Ø©.
                    """
                    response = model.generate_content([chat_prompt, image])
                    
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})